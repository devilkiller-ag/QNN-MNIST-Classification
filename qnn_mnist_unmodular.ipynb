{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import classiq\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from typing import Dict, List\n",
    "from scripts.helper import create_writer\n",
    "\n",
    "from classiq import create_model, synthesize, show, QFunc, QArray, QBit, Output, allocate, RX, RY, RZ, RZZ, RXX, RYY, CZ\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The current version of 'classiq' has been deprecated, and will not be supported as of 2024-01-18. Please run \"pip install -U classiq\" to upgrade the classiq SDK to the latest version.\n",
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Authenticate Classiq\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For setting up device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear Output Files\n",
    "post_process_output_file = open(\"post_process_output.txt\", \"w\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=post_process_output_file)\n",
    "print(\"--------------------------------------------POST PROCESS OUTPUT--------------------------------------------------\", file=post_process_output_file)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=post_process_output_file)\n",
    "post_process_output_file.close()\n",
    "\n",
    "test_loop_output_file = open(\"test_loop_output.txt\", \"w\")\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=test_loop_output_file)\n",
    "print(\"-----------------------------------------------TEST LOOP OUTPUT--------------------------------------------------\", file=test_loop_output_file)\n",
    "print(\"-----------------------------------------------------------------------------------------------------------------\", file=test_loop_output_file)\n",
    "test_loop_output_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_transform(image):\n",
    "    \"\"\"\n",
    "    The input MNIST images are all 28 × 28 px. This function will firstly center-crop \n",
    "    them to 24 × 24 and then down-sample them to 4 × 4 for MNIST. Then we convert \n",
    "    the image pixels into angles for passing them into Rotation gates later for encoding.\n",
    "    \"\"\"\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.CenterCrop(24)(image)\n",
    "    image = transforms.Resize(size = (4,4))(image)\n",
    "    image = image.squeeze()\n",
    "    image_pixels = torch.flatten(image)\n",
    "    angles = torch.sqrt(image_pixels / 256)\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(label):\n",
    "    label_tensor = torch.LongTensor([label])\n",
    "    one_hot_label = torch.nn.functional.one_hot(label_tensor, 10)\n",
    "    return one_hot_label.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0317, 0.0378, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0477, 0.0000, 0.0295, 0.0620, 0.0000, 0.0000]),\n",
       " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0167, 0.0338, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0401, 0.0000, 0.0000]),\n",
       " tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See a random training example\n",
    "import random\n",
    "image, label = train_data[random.randint(0, len(train_data))]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Define the size of the subset\n",
    "subset_size = 64\n",
    "\n",
    "# Create subsets of the datasets\n",
    "train_subset = Subset(train_data, range(subset_size))\n",
    "test_subset = Subset(test_data, range(subset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_subset,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f9c13226950>, <torch.utils.data.dataloader.DataLoader object at 0x7f9c131f5590>)\n",
      "Length of train dataloader: 2 batches of 32\n",
      "Length of test dataloader: 2 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([32, 16]) -> [batch_size, pixel_angle]\n",
      "Label shape: torch.Size([32, 10]) -> [batch_size, label_value]\n"
     ]
    }
   ],
   "source": [
    "data, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Image shape: {data.shape} -> [batch_size, pixel_angle]\")\n",
    "print(f\"Label shape: {label.shape} -> [batch_size, label_value]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def encoding(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function encodes the input data into the qubits. This input data is a 4x4 image pixel values \n",
    "    converted into angle for rotation gates (RX, RY, RZ, RX) in form of a 16x1 vector. \n",
    "    We encode 4 pixels per qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to encode the input data into.\n",
    "    \"\"\"\n",
    "    RX(theta=\"input_0\", target=q[0]) # Pixel 0 on Qubit 0\n",
    "    RY(theta=\"input_1\", target=q[0]) # Pixel 1 on Qubit 0\n",
    "    RZ(theta=\"input_2\", target=q[0]) # Pixel 2 on Qubit 0\n",
    "    RX(theta=\"input_3\", target=q[0]) # Pixel 3 on Qubit 0\n",
    "    \n",
    "    RX(theta=\"input_4\", target=q[1]) # Pixel 4 on Qubit 1\n",
    "    RY(theta=\"input_5\", target=q[1]) # Pixel 5 on Qubit 1\n",
    "    RZ(theta=\"input_6\", target=q[1]) # Pixel 6 on Qubit 1\n",
    "    RX(theta=\"input_7\", target=q[1]) # Pixel 7 on Qubit 1\n",
    "    \n",
    "    RX(theta=\"input_8\", target=q[2]) # Pixel 8 on Qubit 2\n",
    "    RY(theta=\"input_9\", target=q[2]) # Pixel 9 on Qubit 2\n",
    "    RZ(theta=\"input_10\", target=q[2]) # Pixel 10 on Qubit 2\n",
    "    RX(theta=\"input_11\", target=q[2]) # Pixel 11 on Qubit 2\n",
    "    \n",
    "    RX(theta=\"input_12\", target=q[3]) # Pixel 12 on Qubit 3\n",
    "    RY(theta=\"input_13\", target=q[3]) # Pixel 13 on Qubit 3\n",
    "    RZ(theta=\"input_14\", target=q[3]) # Pixel 14 on Qubit 3\n",
    "    RX(theta=\"input_15\", target=q[3]) # Pixel 15 on Qubit 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def mixing(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the mixing operation on the qubits. \n",
    "    This is done by applying a series of RZZ, RXX, RYY gates to form a\n",
    "    ring connection.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the mixing operation on.\n",
    "    \"\"\"\n",
    "    RZZ(theta=\"weight_0\", target=q[0:2])\n",
    "    RZZ(theta=\"weight_1\", target=q[1:3])\n",
    "    RZZ(theta=\"weight_2\", target=q[2:4])\n",
    "    \n",
    "    RXX(theta=\"weight_4\", target=q[0:2])\n",
    "    RXX(theta=\"weight_5\", target=q[1:3])\n",
    "    RXX(theta=\"weight_6\", target=q[2:4])\n",
    "    \n",
    "    RYY(theta=\"weight_8\", target=q[0:2])\n",
    "    RYY(theta=\"weight_9\", target=q[1:3])\n",
    "    RYY(theta=\"weight_10\", target=q[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def cz_block(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function applies CZ gates between each qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the entanglement operation on.\n",
    "    \"\"\"\n",
    "    CZ(control=q[0], target=q[1])\n",
    "    CZ(control=q[1], target=q[2])\n",
    "    CZ(control=q[2], target=q[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def main(res: Output[QArray[QBit]]) -> None:\n",
    "    \"\"\"\n",
    "    This is the main function from which model will be created. \n",
    "    It calls the other functions to perform the encoding, mixing and entanglement.\n",
    "\n",
    "    Args:\n",
    "        res (Output[QArray[QBit]]): Output QArray of QBits from which the model will be created.\n",
    "    \"\"\"\n",
    "    allocate(4, res)\n",
    "    encoding(q=res)\n",
    "    mixing(q=res)\n",
    "    cz_block(q=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://platform.classiq.io/circuit/59626f2b-bebb-4a9c-ac56-af30e550cb58?version=0.33.0\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = create_model(main)\n",
    "quantum_program = synthesize(model)\n",
    "show(quantum_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    counts: dict = result.value.counts\n",
    "    \n",
    "    # Calculate logits from counts\n",
    "    logits: float = torch.zeros(16)\n",
    "    for key, value in counts.items():\n",
    "        logits[int(key, 2)] = value\n",
    "    \n",
    "    # Trim the logits from length 16 to length 10 since we have only 10 labels\n",
    "    trimmed_logits = logits[:10]\n",
    "    \n",
    "    # Calculate prediction probabilities from logits by normalizing it\n",
    "    pred_probs = torch.nn.functional.normalize(trimmed_logits, dim=0)\n",
    "    \n",
    "    # Convert the prediction probabilities into prediction labels\n",
    "    pred_labels = torch.argmax(pred_probs)\n",
    "    \n",
    "    ### WRITE COUNTS, OUTPUT LOGITS, PRED PROBS, PRED LABELS to a file\n",
    "    output_file = open(\"post_process_output.txt\", \"a\")\n",
    "    print(\"----------------------------------------------------------------------------------------------------------------------------------------------\", file=output_file)\n",
    "    print(f\"COUNTS:: \\n {counts} \\n\", file=output_file)\n",
    "    print(f\"LOGITS:: \\n {logits} \\n\", file=output_file)\n",
    "    print(f\"TRIMMED LOGITS:: \\n {trimmed_logits} \\n\", file=output_file)\n",
    "    print(f\"PREDICTION PROBABILITIES:: \\n {pred_probs} \\n\", file=output_file)\n",
    "    print(f\"PREDICTION LABELS:: \\n {pred_labels} \\n\", file=output_file)\n",
    "    output_file.close()\n",
    "    \n",
    "    return torch.tensor(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: https://platform.classiq.io/circuit/59626f2b-bebb-4a9c-ac56-af30e550cb58?version=0.33.0: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.qlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(model=qnn, input_size=(32, 16), verbose=0, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], col_width=20, row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEARNING_RATE = 1.0\n",
    "\n",
    "# choosing our loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "# choosing our optimizer\n",
    "optimizer = optim.SGD(qnn.parameters(), lr=_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    loss_fn: nn.modules.loss._Loss,\n",
    "    optimizer: optim.Optimizer,\n",
    "    writer: torch.utils.tensorboard.writer.SummaryWriter,\n",
    "    epochs: int = 20,\n",
    ") -> Dict[str, List]:\n",
    "    model.to(device)\n",
    "    \n",
    "    # Setup train loss value\n",
    "    train_loss = 0\n",
    "    \n",
    "    # Create empty results dictionary\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "    }\n",
    "    \n",
    "    # Loop through training steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n----------\")\n",
    "        for batch, (data, label) in enumerate(data_loader):\n",
    "            # Send data to device (GPU or CPU)\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            output = model(data)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(output, label)\n",
    "            train_loss += loss\n",
    "            \n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Calculate loss per epoch and print out what's happening\n",
    "        train_loss /= len(data_loader)\n",
    "        \n",
    "        # Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"Train loss: {train_loss:.5f}\"\n",
    "        )\n",
    "        \n",
    "        # Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        \n",
    "        ### Experiment Tracking ###\n",
    "        # See if there's a writer, if so, log to it\n",
    "        if writer:\n",
    "            # Add loss results to SummaryWriter\n",
    "            writer.add_scalars(\n",
    "                main_tag=\"Loss\", \n",
    "                tag_scalar_dict={\"train_loss\": train_loss,},\n",
    "                global_step=epoch\n",
    "            )\n",
    "            \n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "    \n",
    "    # Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    atol=0\n",
    ") -> float:\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Put the model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Turn on inference mode context manager\n",
    "    with torch.inference_mode():\n",
    "        for data, labels in data_loader:\n",
    "            # Send data to GPU\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            # 1. Forward pass: Let the model predict\n",
    "            predictions = model(data)\n",
    "            \n",
    "            # Get a tensor of booleans, indicating if each label is close to the real label\n",
    "            is_prediction_correct = torch.isclose(predictions.argmax(dim=1), labels.argmax(dim=1), atol=atol)\n",
    "            output_file = open(\"test_loop_output.txt\", \"a\")\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------------------------------------\", file=output_file)\n",
    "            print(f\"LABELS:: \\n {labels} \\n\", file=output_file)\n",
    "            print(f\"PREDICTIONS:: \\n {predictions} \\n\", file=output_file)\n",
    "            print(f\"IS PREDICTIONS CORRECT:: \\n {is_prediction_correct} \\n\", file=output_file)\n",
    "            output_file.close()\n",
    "            \n",
    "            # Count the amount of `True` predictions\n",
    "            num_correct += is_prediction_correct.sum().item()\n",
    "            \n",
    "            # Count the total evaluations\n",
    "            #   the first dimension of `labels` is `batch_size`\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = float(num_correct) / float(total)\n",
    "    print(f\"Test Accuracy of the model: {accuracy * 100:.2f}%\")\n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 01. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs/2024-01-04/data_0.1_percent/linear_entanglement_x3/2_epochs...\n"
     ]
    }
   ],
   "source": [
    "# Create a writer for tracking our experiment\n",
    "writer = create_writer(experiment_name=\"data_0.1_percent\", model_name=\"linear_entanglement_x3\", extra=\"2_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_63607/4157040924.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(pred_probs)\n",
      " 50%|█████     | 1/2 [01:11<01:11, 71.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train loss: 0.19132\n",
      "Epoch: 1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:24<00:00, 72.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train loss: 0.28401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = train(qnn, train_dataloader, loss_fn, optimizer, writer=writer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_loss': [tensor(0.2840, grad_fn=<DivBackward0>),\n",
       "  tensor(0.2840, grad_fn=<DivBackward0>)]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the model results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63607/4157040924.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(pred_probs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model: 9.38%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.375"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test(qnn, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

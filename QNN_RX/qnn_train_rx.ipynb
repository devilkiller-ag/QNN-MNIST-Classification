{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QNN to learn to determine the correct angle for Rx Gate for performing a \"NOT\" Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/miniconda3/envs/mnistenv/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import classiq\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "from classiq import Model ,synthesize\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "from classiq import QReg\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.applications.qnn.datasets import DATALOADER_NOT\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection\n",
    ")\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Flow\n",
    "\n",
    "**Step 1: Define Quantum Layer**\n",
    "\n",
    "Step 1.1: Defining the quantum model and synthesizing it to a quantum circuit\n",
    "\n",
    "Step 1.2: Defining the execute and post-process callables\n",
    "\n",
    "Step 1.3: Defining a torch.nn.Module network\n",
    "\n",
    "**Step 2: Initialise Dataset, Loss Function, and Optimiser**\n",
    "\n",
    "**Step 3: Learning Process**\n",
    "\n",
    "**Step 4: Test the QNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.1: Create Parametric Quantum Circuit (PQC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NUM_QUBITS = 1\n",
    "_REPS = 1\n",
    "_CONNECTIVITY_MAP = \"circular\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rx(md: Model, prefix: str, in_wire=None) -> Dict[str, QReg]:\n",
    "    if in_wire is not None:\n",
    "        kwargs = { \"in_wires\": { \"IN\": in_wire[\"OUT\"] } }\n",
    "    else:\n",
    "        kwargs = {}\n",
    "\n",
    "    hwea_params = HardwareEfficientAnsatz(\n",
    "        num_qubits=_NUM_QUBITS,\n",
    "        connectivity_map=_CONNECTIVITY_MAP,\n",
    "        reps=_REPS,\n",
    "        one_qubit_gates=\"rx\",\n",
    "        two_qubit_gates=[],\n",
    "        parameter_prefix=prefix,\n",
    "    )\n",
    "\n",
    "    return md.HardwareEfficientAnsatz(hwea_params, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "output_1 = add_rx(model, \"input_\")\n",
    "output_2 = add_rx(model, \"weight_\", output_1)\n",
    "\n",
    "quantum_program = synthesize(model.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.2: Create the execution and post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments:MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-process the result, returning a dict:\n",
    "# Note: this function assumes that we only care about\n",
    "#   differentiating a single state (|0>)\n",
    "#   from all the rest of the states.\n",
    "#   In case of a different differentiation, this function should change.\n",
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Take in a `SavedResult` with `ExecutionDetails` value type, and return the\n",
    "    probability of measuring |0> which equals the amount of `|0>` measurements\n",
    "    divided by the total amount of measurements.\n",
    "    \"\"\"\n",
    "    counts: dict = result.value.counts\n",
    "    # The probability of measuring |0>\n",
    "    p_zero: float = counts.get(\"0\", 0.0) / sum(counts.values())\n",
    "    return torch.tensor(p_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1.3: Creating a Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.qlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step  2: Choose a Dataset, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEARNING_RATE = 1.0\n",
    "\n",
    "data_loader = DATALOADER_NOT\n",
    "\n",
    "loss_function = nn.L1Loss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, data_loader: DataLoader, loss_function: nn.modules.loss._Loss, optimizer: optim.Optimizer, epoch: int = 20) -> None:\n",
    "    for index in range(epoch):\n",
    "        print(index, model.qlayer.weight)\n",
    "        for data, label in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Parameter containing:\n",
      "tensor([0.5383], requires_grad=True)\n",
      "1 Parameter containing:\n",
      "tensor([0.7946], requires_grad=True)\n",
      "2 Parameter containing:\n",
      "tensor([1.1364], requires_grad=True)\n",
      "3 Parameter containing:\n",
      "tensor([1.5759], requires_grad=True)\n",
      "4 Parameter containing:\n",
      "tensor([2.1130], requires_grad=True)\n",
      "5 Parameter containing:\n",
      "tensor([2.6135], requires_grad=True)\n",
      "6 Parameter containing:\n",
      "tensor([2.7721], requires_grad=True)\n",
      "7 Parameter containing:\n",
      "tensor([2.9553], requires_grad=True)\n",
      "8 Parameter containing:\n",
      "tensor([2.9797], requires_grad=True)\n",
      "9 Parameter containing:\n",
      "tensor([3.0529], requires_grad=True)\n",
      "10 Parameter containing:\n",
      "tensor([3.0773], requires_grad=True)\n",
      "11 Parameter containing:\n",
      "tensor([3.1262], requires_grad=True)\n",
      "12 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "13 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "14 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "15 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "16 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "17 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "18 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n",
      "19 Parameter containing:\n",
      "tensor([3.1384], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "train(model, data_loader, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(model: nn.Module, data_loader: DataLoader, atol=1e-4) -> float:\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            predictions = model(data)\n",
    "            is_prediction_correct = predictions.isclose(labels, atol=atol)\n",
    "            print(f\"data: {data}\\n labels: {labels}\\n is_prediction_correct: {is_prediction_correct}\\n sum: {is_prediction_correct.sum()}\\n item: {is_prediction_correct.sum().item()}\")\n",
    "            num_correct += is_prediction_correct.sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    accuracy = float(num_correct) / float(total)\n",
    "    print(f\"Test Accuracy of the model: {accuracy*100:.2f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: tensor([[0.0000],\n",
      "        [3.1416]])\n",
      " labels: tensor([0., 1.])\n",
      " is_prediction_correct: tensor([True, True])\n",
      " sum: 2\n",
      " item: 2\n",
      "Test Accuracy of the model: 100.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accuracy(model, data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that the accuracy is 1, meaning a 100% success rate at performing the required transformation (i.e. the network learned to perform a X-gate). We may further test it by printing the value of model.qlayer.weight, which is a tensor of shape (1,1), which should, after training, be close to pi=3.1416."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnistenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

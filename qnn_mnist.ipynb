{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import classiq\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from typing import Dict\n",
    "from classiq import create_model, synthesize, show, QFunc, QArray, QBit, Output, allocate, RX, RY, RZ, RZZ, RXX, RYY, CZ\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")\n",
    "\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_transform(image):\n",
    "    \"\"\"\n",
    "    The input MNIST images are all 28 × 28. This function will firstly center-crop \n",
    "    them to 24 × 24 and then down-sample them to 4 × 4 for MNIST.\n",
    "    \"\"\"\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.CenterCrop(24)(image)\n",
    "    image = transforms.Resize(size = (4,4))(image)\n",
    "    image = image.squeeze()\n",
    "    image_pixels = torch.flatten(image)\n",
    "    amplitudes = torch.sqrt(image_pixels / 256)\n",
    "    \n",
    "    return amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0317, 0.0378, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0477, 0.0000, 0.0295, 0.0620, 0.0000, 0.0000]),\n",
       " 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_data,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f8dd13ae190>, <torch.utils.data.dataloader.DataLoader object at 0x7f8dd1390250>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def encoding(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function encodes the input data into the qubits. This input data is a 4x4 image pixel values \n",
    "    converted into angle for rotation gates (RX, RY, RZ, RX) in form of a 16x1 vector. \n",
    "    We encode 4 pixels per qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to encode the input data into.\n",
    "    \"\"\"\n",
    "    RX(theta=\"input_0\", target=q[0]) # Pixel 0 on Qubit 0\n",
    "    RY(theta=\"input_1\", target=q[0]) # Pixel 1 on Qubit 0\n",
    "    RZ(theta=\"input_2\", target=q[0]) # Pixel 2 on Qubit 0\n",
    "    RX(theta=\"input_3\", target=q[0]) # Pixel 3 on Qubit 0\n",
    "    \n",
    "    RX(theta=\"input_4\", target=q[1]) # Pixel 4 on Qubit 1\n",
    "    RY(theta=\"input_5\", target=q[1]) # Pixel 5 on Qubit 1\n",
    "    RZ(theta=\"input_6\", target=q[1]) # Pixel 6 on Qubit 1\n",
    "    RX(theta=\"input_7\", target=q[1]) # Pixel 7 on Qubit 1\n",
    "    \n",
    "    RX(theta=\"input_8\", target=q[2]) # Pixel 8 on Qubit 2\n",
    "    RY(theta=\"input_9\", target=q[2]) # Pixel 9 on Qubit 2\n",
    "    RZ(theta=\"input_10\", target=q[2]) # Pixel 10 on Qubit 2\n",
    "    RX(theta=\"input_11\", target=q[2]) # Pixel 11 on Qubit 2\n",
    "    \n",
    "    RX(theta=\"input_12\", target=q[3]) # Pixel 12 on Qubit 3\n",
    "    RY(theta=\"input_13\", target=q[3]) # Pixel 13 on Qubit 3\n",
    "    RZ(theta=\"input_14\", target=q[3]) # Pixel 14 on Qubit 3\n",
    "    RX(theta=\"input_15\", target=q[3]) # Pixel 15 on Qubit 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def mixing(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the mixing operation on the qubits. \n",
    "    This is done by applying a series of RZZ, RXX, RYY gates to form a\n",
    "    ring connection.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the mixing operation on.\n",
    "    \"\"\"\n",
    "    RZZ(theta=\"weight_0\", target=q[0:2])\n",
    "    RZZ(theta=\"weight_1\", target=q[1:3])\n",
    "    RZZ(theta=\"weight_2\", target=q[2:4])\n",
    "    # RZZ(theta=\"weight_3\", target=q[0:3])\n",
    "    \n",
    "    RXX(theta=\"weight_4\", target=q[0:2])\n",
    "    RXX(theta=\"weight_5\", target=q[1:3])\n",
    "    RXX(theta=\"weight_6\", target=q[2:4])\n",
    "    # RXX(theta=\"weight_7\", target=q[3:1])\n",
    "    \n",
    "    RYY(theta=\"weight_8\", target=q[0:2])\n",
    "    RYY(theta=\"weight_9\", target=q[1:3])\n",
    "    RYY(theta=\"weight_10\", target=q[2:4])\n",
    "    # RYY(theta=\"weight_11\", target=q[3:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def cz_block(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the entanglement operation on the qubits by applying\n",
    "    CZ gates between each qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the entanglement operation on.\n",
    "    \"\"\"\n",
    "    CZ(control=q[0], target=q[1])\n",
    "    CZ(control=q[1], target=q[2])\n",
    "    CZ(control=q[2], target=q[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def main(res: Output[QArray[QBit]]) -> None:\n",
    "    \"\"\"\n",
    "    This is the main function from which model will be created. \n",
    "    It calls the other functions to perform the encoding, mixing and entanglement.\n",
    "\n",
    "    Args:\n",
    "        res (Output[QArray[QBit]]): Output QArray of QBits from which the model will be created.\n",
    "    \"\"\"\n",
    "    allocate(4, res)\n",
    "    encoding(q=res)\n",
    "    mixing(q=res)\n",
    "    cz_block(q=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://platform.classiq.io/circuit/11d43543-2ebb-41bf-9e62-b1c196316406?version=0.33.0\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = create_model(main)\n",
    "quantum_program = synthesize(model)\n",
    "show(quantum_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    counts: dict = result.value.counts\n",
    "    # The probability of measuring |0>\n",
    "    print(f\"counts: {counts}\")\n",
    "    p_zero: float = counts.get(\"0\", 0.0) / sum(counts.values())\n",
    "    return torch.tensor(p_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.qlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: https://platform.classiq.io/circuit/11d43543-2ebb-41bf-9e62-b1c196316406?version=0.33.0: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "qnn = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

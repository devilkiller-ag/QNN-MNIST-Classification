{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifs\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\classiq\\_internals\\authentication\\token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import classiq\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from typing import Dict\n",
    "from classiq import create_model, synthesize, show, QFunc, QArray, QBit, Output, allocate, RX, RY, RZ, RZZ, RXX, RYY, CZ\n",
    "from classiq.builtin_functions import HardwareEfficientAnsatz\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")\n",
    "\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classical Layer for Image Commpression:\n",
    "The input MNIST images are all 28 × 28. This Classical Layer will firstly center-crop them to 24 × 24 and\n",
    "then down-sample them to 4 × 4 for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_compression(x):\n",
    "    \"\"\"\n",
    "    The input MNIST images are all 28 × 28. This function will firstly center-crop \n",
    "    them to 24 × 24 and then down-sample them to 4 × 4 for MNIST.\n",
    "    \"\"\"\n",
    "    transform = transforms.CenterCrop(24) \n",
    "    image_crop = transform(x)\n",
    "    image_crop_reshaped = image_crop.view(1, -1, 24, 24)\n",
    "    transform = transforms.Resize(size = (4,4))\n",
    "    resize_image = transform(image_crop_reshaped)\n",
    "    resize_image_squeezed = resize_image.squeeze()\n",
    "    res = torch.flatten(resize_image_squeezed)\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def encoding(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function encodes the input data into the qubits. This input data is a 4x4 image pixel values \n",
    "    converted into angle for rotation gates (RX, RY, RZ, RX) in form of a 16x1 vector. \n",
    "    We encode 4 pixels per qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to encode the input data into.\n",
    "    \"\"\"\n",
    "    RX(theta=\"input_0\", target=q[0]) # Pixel 0 on Qubit 0\n",
    "    RY(theta=\"input_1\", target=q[0]) # Pixel 1 on Qubit 0\n",
    "    RZ(theta=\"input_2\", target=q[0]) # Pixel 2 on Qubit 0\n",
    "    RX(theta=\"input_3\", target=q[0]) # Pixel 3 on Qubit 0\n",
    "    \n",
    "    RX(theta=\"input_4\", target=q[1]) # Pixel 4 on Qubit 1\n",
    "    RY(theta=\"input_5\", target=q[1]) # Pixel 5 on Qubit 1\n",
    "    RZ(theta=\"input_6\", target=q[1]) # Pixel 6 on Qubit 1\n",
    "    RX(theta=\"input_7\", target=q[1]) # Pixel 7 on Qubit 1\n",
    "    \n",
    "    RX(theta=\"input_8\", target=q[2]) # Pixel 8 on Qubit 2\n",
    "    RY(theta=\"input_9\", target=q[2]) # Pixel 9 on Qubit 2\n",
    "    RZ(theta=\"input_10\", target=q[2]) # Pixel 10 on Qubit 2\n",
    "    RX(theta=\"input_11\", target=q[2]) # Pixel 11 on Qubit 2\n",
    "    \n",
    "    RX(theta=\"input_12\", target=q[3]) # Pixel 12 on Qubit 3\n",
    "    RY(theta=\"input_13\", target=q[3]) # Pixel 13 on Qubit 3\n",
    "    RZ(theta=\"input_14\", target=q[3]) # Pixel 14 on Qubit 3\n",
    "    RX(theta=\"input_15\", target=q[3]) # Pixel 15 on Qubit 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def mixing(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the mixing operation on the qubits. \n",
    "    This is done by applying a series of RZZ, RXX, RYY gates to form a\n",
    "    ring connection.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the mixing operation on.\n",
    "    \"\"\"\n",
    "    RZZ(theta=\"weight_0\", target=q[0:2])\n",
    "    RZZ(theta=\"weight_1\", target=q[1:3])\n",
    "    RZZ(theta=\"weight_2\", target=q[2:4])\n",
    "    # RZZ(theta=\"weight_3\", target=q[0:3])\n",
    "    \n",
    "    RXX(theta=\"weight_4\", target=q[0:2])\n",
    "    RXX(theta=\"weight_5\", target=q[1:3])\n",
    "    RXX(theta=\"weight_6\", target=q[2:4])\n",
    "    # RXX(theta=\"weight_7\", target=q[3:1])\n",
    "    \n",
    "    RYY(theta=\"weight_8\", target=q[0:2])\n",
    "    RYY(theta=\"weight_9\", target=q[1:3])\n",
    "    RYY(theta=\"weight_10\", target=q[2:4])\n",
    "    # RYY(theta=\"weight_11\", target=q[3:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def cz_block(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the entanglement operation on the qubits by applying\n",
    "    CZ gates between each qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the entanglement operation on.\n",
    "    \"\"\"\n",
    "    CZ(control=q[0], target=q[1])\n",
    "    CZ(control=q[1], target=q[2])\n",
    "    CZ(control=q[2], target=q[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def main(res: Output[QArray[QBit]]) -> None:\n",
    "    \"\"\"\n",
    "    This is the main function from which model will be created. \n",
    "    It calls the other functions to perform the encoding, mixing and entanglement.\n",
    "\n",
    "    Args:\n",
    "        res (Output[QArray[QBit]]): Output QArray of QBits from which the model will be created.\n",
    "    \"\"\"\n",
    "    allocate(4, res)\n",
    "    encoding(q=res)\n",
    "    mixing(q=res)\n",
    "    cz_block(q=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://platform.classiq.io/circuit/63fae884-506e-4554-bd2b-34cfdeb20777?version=0.33.0\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = create_model(main)\n",
    "quantum_program = synthesize(model)\n",
    "# show(quantum_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experimenting from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    counts: dict = result.value.counts\n",
    "    # The probability of measuring |0>\n",
    "    print(f\"counts: {counts}\")\n",
    "    p_zero: float = counts.get(\"0\", 0.0) / sum(counts.values())\n",
    "    return torch.tensor(p_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.qlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnn = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CTDataset(Dataset):\n",
    "#     def __init__(self, filepath):\n",
    "#         self.x, self.y = torch.load(filepath)\n",
    "#         self.x = self.x / 255.\n",
    "#         self.y = F.one_hot(self.y, num_classes=10).to(float)\n",
    "#     def __len__(self): \n",
    "#         return self.x.shape[0]\n",
    "#     def __getitem__(self, ix): \n",
    "#         return self.x[ix], self.y[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEARNING_RATE = 1.0\n",
    "# load dataset\n",
    "# train_ds = CTDataset('MNIST_DATASET/processed/training.pt')\n",
    "# test_ds = CTDataset('MNIST_DATASET/processed/test.pt')\n",
    "# train_dl = DataLoader(train_ds, batch_size=5)\n",
    "\n",
    "# choosing our loss function\n",
    "loss_func = nn.L1Loss()\n",
    "\n",
    "# choosing our optimizer\n",
    "optimizer = optim.SGD(qnn.parameters(), lr=_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = torch.load('MNIST_DATASET/processed/training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = x[1]\n",
    "train_label = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_image.numpy())\n",
    "plt.title(f'Number is {train_label.numpy()}')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asifs\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ct_image = classical_compression(train_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0, 229,   0,   0, 244,  36,  54,   0,   0,   2,   3,   0, 252,\n",
      "          0,   0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "print(ct_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, dtype=torch.uint8)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     16\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 19\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mct_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, loss_func, optimizer, epoch)\u001b[0m\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[1;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output, label)\n\u001b[0;32m     15\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\classiq\\applications\\qnn\\qlayer.py:184\u001b[0m, in \u001b[0;36mQLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQLayerFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[no-untyped-call]\u001b[39;49;00m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_program\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_process\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\function.py:539\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    538\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[0;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    547\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\classiq\\applications\\qnn\\qlayer.py:66\u001b[0m, in \u001b[0;36mQLayerFunction.forward\u001b[1;34m(ctx, inputs, weights, quantum_program, execute, post_process)\u001b[0m\n\u001b[0;32m     61\u001b[0m ctx\u001b[38;5;241m.\u001b[39mpost_process \u001b[38;5;241m=\u001b[39m post_process\n\u001b[0;32m     62\u001b[0m ctx\u001b[38;5;241m.\u001b[39mquantum_gradient \u001b[38;5;241m=\u001b[39m SimpleQuantumGradient(\n\u001b[0;32m     63\u001b[0m     quantum_program, execute, post_process\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 66\u001b[0m ctx\u001b[38;5;241m.\u001b[39mbatch_size, ctx\u001b[38;5;241m.\u001b[39mnum_in_features \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_single_layer_circuit(weights):\n\u001b[0;32m     68\u001b[0m     ctx\u001b[38;5;241m.\u001b[39mnum_weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "label=train_label\n",
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: torch.Tensor,\n",
    "    loss_func: nn.modules.loss._Loss,\n",
    "    optimizer: optim.Optimizer,\n",
    "    epoch: int = 20,\n",
    ") -> None:\n",
    "    for index in range(epoch):\n",
    "        for data in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            print(data)\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "train(qnn, ct_image, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

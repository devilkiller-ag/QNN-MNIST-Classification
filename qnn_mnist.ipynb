{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/classiq/_internals/authentication/token_manager.py:82: UserWarning: Device is already registered.\n",
      "Generating a new refresh token should only be done if the current refresh token is compromised.\n",
      "To do so, set the overwrite parameter to true\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import classiq\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from classiq import create_model, synthesize, show, QFunc, QArray, QBit, Output, allocate, RX, RY, RZ, RZZ, RXX, RYY, CZ\n",
    "from classiq.applications.qnn import QLayer\n",
    "from classiq.execution import execute_qnn\n",
    "from classiq.synthesis import SerializedQuantumProgram\n",
    "\n",
    "from classiq.applications.qnn.types import (\n",
    "    MultipleArguments,\n",
    "    SavedResult,\n",
    "    ResultsCollection,\n",
    ")\n",
    "\n",
    "classiq.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_transform(image):\n",
    "    \"\"\"\n",
    "    The input MNIST images are all 28 × 28 px. This function will firstly center-crop \n",
    "    them to 24 × 24 and then down-sample them to 4 × 4 for MNIST. Then we convert \n",
    "    the image pixels into angles for passing them into Rotation gates later for encoding.\n",
    "    \"\"\"\n",
    "    image = transforms.ToTensor()(image)\n",
    "    image = transforms.CenterCrop(24)(image)\n",
    "    image = transforms.Resize(size = (4,4))(image)\n",
    "    image = image.squeeze()\n",
    "    image_pixels = torch.flatten(image)\n",
    "    angles = torch.sqrt(image_pixels / 256)\n",
    "    \n",
    "    return angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_transform(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=input_transform,\n",
    "    target_transform=target_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.0000, 0.0000, 0.0317, 0.0378, 0.0000, 0.0336, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0477, 0.0000, 0.0295, 0.0620, 0.0000, 0.0000]),\n",
       " 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first training example\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Define the size of the subset\n",
    "subset_size = 64\n",
    "\n",
    "# Create subsets of the datasets\n",
    "train_subset = Subset(train_data, range(subset_size))\n",
    "test_subset = Subset(test_data, range(subset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(train_subset,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_subset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7f905f89b9d0>, <torch.utils.data.dataloader.DataLoader object at 0x7f906042cfd0>)\n",
      "Length of train dataloader: 2 batches of 32\n",
      "Length of test dataloader: 2 batches of 32\n"
     ]
    }
   ],
   "source": [
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def encoding(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function encodes the input data into the qubits. This input data is a 4x4 image pixel values \n",
    "    converted into angle for rotation gates (RX, RY, RZ, RX) in form of a 16x1 vector. \n",
    "    We encode 4 pixels per qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to encode the input data into.\n",
    "    \"\"\"\n",
    "    RX(theta=\"input_0\", target=q[0]) # Pixel 0 on Qubit 0\n",
    "    RY(theta=\"input_1\", target=q[0]) # Pixel 1 on Qubit 0\n",
    "    RZ(theta=\"input_2\", target=q[0]) # Pixel 2 on Qubit 0\n",
    "    RX(theta=\"input_3\", target=q[0]) # Pixel 3 on Qubit 0\n",
    "    \n",
    "    RX(theta=\"input_4\", target=q[1]) # Pixel 4 on Qubit 1\n",
    "    RY(theta=\"input_5\", target=q[1]) # Pixel 5 on Qubit 1\n",
    "    RZ(theta=\"input_6\", target=q[1]) # Pixel 6 on Qubit 1\n",
    "    RX(theta=\"input_7\", target=q[1]) # Pixel 7 on Qubit 1\n",
    "    \n",
    "    RX(theta=\"input_8\", target=q[2]) # Pixel 8 on Qubit 2\n",
    "    RY(theta=\"input_9\", target=q[2]) # Pixel 9 on Qubit 2\n",
    "    RZ(theta=\"input_10\", target=q[2]) # Pixel 10 on Qubit 2\n",
    "    RX(theta=\"input_11\", target=q[2]) # Pixel 11 on Qubit 2\n",
    "    \n",
    "    RX(theta=\"input_12\", target=q[3]) # Pixel 12 on Qubit 3\n",
    "    RY(theta=\"input_13\", target=q[3]) # Pixel 13 on Qubit 3\n",
    "    RZ(theta=\"input_14\", target=q[3]) # Pixel 14 on Qubit 3\n",
    "    RX(theta=\"input_15\", target=q[3]) # Pixel 15 on Qubit 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def mixing(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function performs the mixing operation on the qubits. \n",
    "    This is done by applying a series of RZZ, RXX, RYY gates to form a\n",
    "    ring connection.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the mixing operation on.\n",
    "    \"\"\"\n",
    "    RZZ(theta=\"weight_0\", target=q[0:2])\n",
    "    RZZ(theta=\"weight_1\", target=q[1:3])\n",
    "    RZZ(theta=\"weight_2\", target=q[2:4])\n",
    "    \n",
    "    RXX(theta=\"weight_4\", target=q[0:2])\n",
    "    RXX(theta=\"weight_5\", target=q[1:3])\n",
    "    RXX(theta=\"weight_6\", target=q[2:4])\n",
    "    \n",
    "    RYY(theta=\"weight_8\", target=q[0:2])\n",
    "    RYY(theta=\"weight_9\", target=q[1:3])\n",
    "    RYY(theta=\"weight_10\", target=q[2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def cz_block(q: QArray[QBit]) -> None:\n",
    "    \"\"\"\n",
    "    This function applies CZ gates between each qubit.\n",
    "\n",
    "    Args:\n",
    "        q (QArray[QBit]): Array of four Qubits to apply the entanglement operation on.\n",
    "    \"\"\"\n",
    "    CZ(control=q[0], target=q[1])\n",
    "    CZ(control=q[1], target=q[2])\n",
    "    CZ(control=q[2], target=q[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@QFunc\n",
    "def main(res: Output[QArray[QBit]]) -> None:\n",
    "    \"\"\"\n",
    "    This is the main function from which model will be created. \n",
    "    It calls the other functions to perform the encoding, mixing and entanglement.\n",
    "\n",
    "    Args:\n",
    "        res (Output[QArray[QBit]]): Output QArray of QBits from which the model will be created.\n",
    "    \"\"\"\n",
    "    allocate(4, res)\n",
    "    encoding(q=res)\n",
    "    mixing(q=res)\n",
    "    cz_block(q=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: https://platform.classiq.io/circuit/79ef146a-a004-4a95-ba01-72651b5bc3a5?version=0.33.0\n"
     ]
    }
   ],
   "source": [
    "# Create a model\n",
    "model = create_model(main)\n",
    "quantum_program = synthesize(model)\n",
    "show(quantum_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(quantum_program: SerializedQuantumProgram, arguments: MultipleArguments) -> ResultsCollection:\n",
    "    return execute_qnn(quantum_program, arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(result: SavedResult) -> torch.Tensor:\n",
    "    counts: dict = result.value.counts\n",
    "    # The probability of measuring |0>\n",
    "    # print(f\"counts: {counts}\")\n",
    "    p_zero: float = counts.get(\"0\", 0.0) / sum(counts.values())\n",
    "    return torch.tensor(p_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.qlayer = QLayer(\n",
    "            quantum_program,\n",
    "            execute,\n",
    "            post_process,\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.qlayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: https://platform.classiq.io/circuit/79ef146a-a004-4a95-ba01-72651b5bc3a5?version=0.33.0: Operation not supported\n"
     ]
    }
   ],
   "source": [
    "qnn = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LEARNING_RATE = 1.0\n",
    "\n",
    "# choosing our loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "# choosing our optimizer\n",
    "optimizer = optim.SGD(qnn.parameters(), lr=_LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    loss_fn: nn.modules.loss._Loss,\n",
    "    optimizer: optim.Optimizer,\n",
    "    epochs: int = 20,\n",
    ") -> None:\n",
    "    train_loss = 0\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(f\"Epoch: {epoch}\\n----------\")\n",
    "        for batch, (data, label) in enumerate(data_loader):\n",
    "            # Send data to device (GPU or CPU)\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            \n",
    "            # 1. Forward pass\n",
    "            output = model(data)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(output, label)\n",
    "            train_loss += loss\n",
    "            \n",
    "            # 3. Optimizer zero grad\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 4. Loss backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5. Optimizer step\n",
    "            optimizer.step()\n",
    "    \n",
    "        # Calculate loss per epoch and print out what's happening\n",
    "        train_loss /= len(data_loader)\n",
    "        print(f\"Train loss: {train_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/devilkillerag/document/python_pro/QNN-MNIST-Classification/qnn/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:59<18:48, 59.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.43750\n",
      "Epoch: 1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [02:02<18:28, 61.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 6.65625\n",
      "Epoch: 2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [02:58<16:41, 58.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 7.76562\n",
      "Epoch: 3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [04:03<16:23, 61.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.32031\n",
      "Epoch: 4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [05:00<14:54, 59.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.59766\n",
      "Epoch: 5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [05:57<13:45, 59.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.73633\n",
      "Epoch: 6\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [06:52<12:30, 57.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.80566\n",
      "Epoch: 7\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [07:48<11:23, 56.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.84033\n",
      "Epoch: 8\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [08:44<10:25, 56.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.85767\n",
      "Epoch: 9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [09:41<09:27, 56.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.86633\n",
      "Epoch: 10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [10:36<08:27, 56.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87067\n",
      "Epoch: 11\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [11:31<07:27, 55.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87283\n",
      "Epoch: 12\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [12:36<06:50, 58.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87392\n",
      "Epoch: 13\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [13:32<05:46, 57.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87446\n",
      "Epoch: 14\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [14:29<04:47, 57.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87473\n",
      "Epoch: 15\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [15:24<03:47, 56.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87486\n",
      "Epoch: 16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [16:21<02:50, 56.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87493\n",
      "Epoch: 17\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [17:17<01:52, 56.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87497\n",
      "Epoch: 18\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [18:23<00:59, 59.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87498\n",
      "Epoch: 19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [19:28<00:00, 58.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 8.87499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(qnn, train_dataloader, loss_fn, optimizer, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    atol=1e-4\n",
    ") -> float:\n",
    "    num_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Put the model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Turn on inference mode context manager\n",
    "    with torch.inference_mode():\n",
    "        for data, labels in data_loader:\n",
    "            # Send data to GPU\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            \n",
    "            # 1. Forward pass: Let the model predict\n",
    "            predictions = model(data)\n",
    "            \n",
    "            # Get a tensor of booleans, indicating if each label is close to the real label\n",
    "            is_prediction_correct = torch.isclose(predictions, labels.type(torch.float32), atol=atol)\n",
    "            print(\"Label: \", labels)\n",
    "            print(\"predictions: \", predictions)\n",
    "            print(\"is_prediction_correct: \", is_prediction_correct)\n",
    "            \n",
    "            # Count the amount of `True` predictions\n",
    "            num_correct += is_prediction_correct.sum().item()\n",
    "            \n",
    "            # Count the total evaluations\n",
    "            #   the first dimension of `labels` is `batch_size`\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = float(num_correct) / float(total)\n",
    "    print(f\"Test Accuracy of the model: {accuracy*100:.2f}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1])\n",
      "predictions:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "is_prediction_correct:  tensor([False, False, False,  True, False, False, False, False, False, False,\n",
      "         True, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False, False, False, False,  True, False, False,  True, False,\n",
      "        False, False])\n",
      "Label:  tensor([3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0,\n",
      "        4, 1, 9, 5, 7, 8, 9, 3])\n",
      "predictions:  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "is_prediction_correct:  tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False,  True, False, False, False, False, False, False,\n",
      "        False, False])\n",
      "Test Accuracy of the model: 9.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09375"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(qnn, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
